# Self-Supervised Representation Learning

Given a task and enough labels, supervised learning can solve it really well. Good performance usually requires a decent amount of labels, but collecting manual labels is expensive \(i.e. ImageNet\) and hard to be scaled up. Considering the amount of unlabelled data \(e.g. free text, all the images on the Internet\) is substantially more than a limited number of human curated labelled datasets, it is kinda wasteful not to use them. However, unsupervised learning is not easy and usually works much less efficiently than supervised learning.

[https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html\#contrastive-predictive-coding](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html#contrastive-predictive-coding)

